# -*- coding: utf-8 -*-
"""Sushant_MulLinReg_EXPT3_Self.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g8R8DuFQahP0GMDPX5Y7fVDSm09_oiSO
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Connecting to Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Importing the dataset
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Student_Performance.csv')

'''# Dropping the 'Cold' column as out of 2,700 rows, there are only 10 rows with '1' value for Cold.
# '1' in Hot indicates Hot climate and '0' in Hot indicates not only Moderate but now Cold as well.
# Dropping the 'last_update' column as its value is same for all rows.
data1 = data.copy()
data1.drop(columns=['last_update', 'Cold'], inplace=True)'''

'''# Converting text to number in last column
pollutant_avg_bin_numeric = list()
for value in data1['pollutant_avg_bin']:
    if value == "Low":
        pollutant_avg_bin_numeric.append(1)
    if value == "Moderate":
        pollutant_avg_bin_numeric.append(2)
    if value == "High":
        pollutant_avg_bin_numeric.append(3)
    if value == "Severe":
        pollutant_avg_bin_numeric.append(4)
data1['pollutant_avg_bin'] = pollutant_avg_bin_numeric'''

e_a = list()
data1 = data.copy()
for value in data1['Extracurricular Activities']:
    if value == "Yes":
        e_a.append(1)
    else:
        e_a.append(0)
data1['Extracurricular Activities'] = e_a

data1

# Mapping for Understanding   # Interpretation for Prediction
# X1 = State                  # State the locality is in
# X2 = City                   # City the locality is near to
# X3 = Station                # Station the locality is near to (more accuracy as a city can have multiple locations)
# X4 = Station Code           # Station code of data provider (like APPCB, etc.)
# X5 = Latitude               # Exact latitude of locality
# X6 = Longitude              # Exact longitude of locality
# X7 = Pollutant ID           # Pollutant whose prediction we want
# X8 = Pollutant Min          # Maximum amount recorded for that pollutant
# X9 = Pollutant Max          # Minimum amount recorded for that pollutant
# # Y = Pollutant Avg         # The amount of pollutant predicted
# X10 = Hot                   # Air Temperature of the locality
# X11 = Pollutant Max Min Avg # Average of Maximum and Minimum amount recorded for that pollutant
# X12 = Pollutant Avg Bin     # Doesn't make sense. If I am already inputting that it is 'Low' pollution, then why am I asking for a value?

"""Now, we have all independant variables extracted and also the expected dependant variable extracted from our dataset. Now actual action begins..."""

# Feature scaling the columns
for column in data1.columns:
    max = data1[f'{column}'].max()
    #data2['state'] = (data2['state'] - data2['state'].mean()) / data2['state'].std()
    data1[f'{column}'] = data1[f'{column}'] / max
data1

# Cost Function
def se(Y_tru, Y_pre):
    return (Y_pre - Y_tru) ** 2

data1.shape[1]

# Initialization
m = data1.shape[0]
θ_len = data1.shape[1]
θ = list()
for i in range(0, θ_len):
    θ.append(0)
θ_arr = np.array(θ)
U = np.array(θ)
CU = np.array(θ)
α = 0.001
CF = 0
CFL = list()
i = 0
Y_pre = 0
# Define the column indices to include
include_columns = [0, 1, 2, 3, 4]
TSE = 0
while True:
    print(f'Epoch {i+1}')
    for index, row in data1.iterrows():
        # X(i) has got X1, X2, X3, ...
        X = np.array(row[include_columns])
        # Insert a 1 at the start of the numpy array (X0 = 1)
        X = np.insert(X, 0, 1)
        print(θ_arr, X)
        Y_tru = row[5]
        Y_pred = np.transpose(θ_arr) * X
        Y_pred = np.sum(Y_pred)
        print(index, Y_pred, Y_tru)
        SE = se(Y_tru, Y_pred)
        print(SE)
        TSE += SE
        # Update parameter
        for cell in range(0, θ_len):
            U[cell] = (Y_pred - Y_tru) * X[cell]
            CU[cell] += U[cell]
            print(f'Epoch {i}: For cell {cell} of row {index}, value of cell was {X[cell]} and update value is {U[cell]}')
    print(f'Cumulative Update: {CU}')
    # Updating the θ values
    for cell in range(0, θ_len):
        print(f'θ[{cell}]: {θ_arr[cell]}')
        print(f'CU[{cell}]: {CU[cell]}')
        print(f'α: {α}, m: {m}')
        θ_arr[cell] = θ_arr[cell] - (α / m) * CU[cell]
        print(f'Updated θ[{cell}] is {θ_arr[cell]}')
    print(f'Total Squared Error for Epoch {i+1}:', TSE)
    CF = (1 / (2 * m)) * TSE
    print(f'Cost Function for Epoch {i+1}:', CF)
    CFL.append(CF)
    CU = np.zeros_like(θ_arr)
    i += 1
    if i == 3:
        break
for i in range(0, 2):
    print(f'For Epoch {i}, Cost Function {CFL[i]}')
# Discrepancy might be due to not performing feature scaling
# Values accross table range from 0 to 400.
# All the values should be between 0 and 1 as I have heard.

# Plotting
print(CFL)
plt.plot(CFL)
plt.xlabel('Epochs')
plt.ylabel('CF')